{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51339550-b3c7-4422-afa3-675e882f7b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the dataset\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"adult 3.csv\")\n",
    "\n",
    "print(\"\\nTop 15 rows:\")\n",
    "print(data.head(15))\n",
    "\n",
    "print(\"\\nShape of the dataset:\", data.shape)\n",
    "\n",
    "print(\"\\nNull values in each column:\")\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f307324e-6273-4df2-9b1e-e6f1f0138dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Replace unclear values ('?') with 'Unknown'\n",
    "data['workclass'] = data['workclass'].replace('?', 'Unknown')\n",
    "data['occupation'] = data['occupation'].replace('?', 'Unknown')\n",
    "data['native-country'] = data['native-country'].replace('?', 'Unknown')\n",
    "\n",
    "print(\"\\nWorkclass values:\")\n",
    "print(data['workclass'].value_counts())\n",
    "\n",
    "print(\"\\nOccupation values:\")\n",
    "print(data['occupation'].value_counts())\n",
    "\n",
    "print(\"\\nNative-country values:\")\n",
    "print(data['native-country'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5f8c54-9a09-4880-be65-95bfcff1bff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Remove irrelevant or very rare categories\n",
    "data = data[data['workclass'] != 'Without-pay']\n",
    "data = data[data['workclass'] != 'Never-worked']\n",
    "data = data[data['education'] != '1st-4th']\n",
    "data = data[data['education'] != '5th-6th']\n",
    "data = data[data['education'] != 'Preschool']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b15c0e-389d-4fa4-980d-fee9c6429572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Handle outliers in age\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.boxplot(data['age'])\n",
    "plt.title(\"Boxplot of Age\")\n",
    "plt.ylabel(\"Age\")\n",
    "plt.show()\n",
    "\n",
    "data = data[(data['age'] >= 17) & (data['age'] <= 75)]\n",
    "\n",
    "print(\"\\nShape after removing outliers and rare categories:\", data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0918a29-963a-4212-819e-6974c2a65645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Drop 'education' column (already covered by 'education-num')\n",
    "data = data.drop(columns=['education'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0077943d-36e5-42c3-9085-4c6a0dc7e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Drop duplicate rows\n",
    "data = data.drop_duplicates()\n",
    "print(\"\\nShape after removing duplicates:\", data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328eddb6-6949-47f0-a6cd-e9e76e5e6b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Encode categorical columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define categorical columns\n",
    "categorical_cols = ['workclass', 'marital-status', 'occupation',\n",
    "                    'relationship', 'race', 'gender', 'native-country']\n",
    "\n",
    "# Dictionary to hold encoders\n",
    "encoders = {}\n",
    "\n",
    "# Encode and save each encoder\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    encoders[col] = le\n",
    "    joblib.dump(le, f\"{col}_encoder.pkl\")  # Save encoder\n",
    "\n",
    "print(\"All LabelEncoders have been saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343bff30-040a-4d5e-8ddc-42da6a4bcded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Split data into features (X) and target (Y)\n",
    "X = data.drop(columns=['income'])\n",
    "Y = data['income']\n",
    "\n",
    "print(\"\\nX shape:\", X.shape)\n",
    "print(\"Y shape:\", Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00507805-1f6d-4977-8c00-d0041ba34849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Scale the Data and Split into Train/Test Sets\n",
    "# Scale the features so all values are between 0 and 1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Show scaled features as a DataFrame\n",
    "scaled_df = pd.DataFrame(X, columns=data.drop(columns=['income']).columns)\n",
    "\n",
    "print(\"\\nScaled feature sample (first 5 rows):\")\n",
    "print(scaled_df.head())\n",
    "\n",
    "# Split the data into training and testing sets (80-20) with class balance\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.2, random_state=23, stratify=Y)\n",
    "\n",
    "print(\"\\nTraining features shape:\", xtrain.shape)\n",
    "print(\"Testing features shape:\", xtest.shape)\n",
    "print(\"Training labels shape:\", ytrain.shape)\n",
    "print(\"Testing labels shape:\", ytest.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b951d2d7-1dbc-4c06-8219-5cb41cf522c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Train and Evaluate a K-Nearest Neighbors (KNN) Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Fit the model on training data\n",
    "knn.fit(xtrain, ytrain)\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = knn.predict(xtest)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(ytest, predictions)\n",
    "\n",
    "print(\"\\nKNN Accuracy on test set:\", round(accuracy * 100, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f42e45-6d1c-4ea6-9620-ea7849980fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Train and Evaluate Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train on the training data\n",
    "logreg.fit(xtrain, ytrain)\n",
    "\n",
    "# Predict on the test set\n",
    "logreg_pred = logreg.predict(xtest)\n",
    "\n",
    "# Evaluate accuracy\n",
    "logreg_acc = accuracy_score(ytest, logreg_pred)\n",
    "\n",
    "print(\"Logistic Regression Accuracy on test set:\", round(logreg_acc * 100, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6990e01-57a4-412c-a961-ad5495376f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Train and Evaluate a Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize decision tree model\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model\n",
    "dtree.fit(xtrain, ytrain)\n",
    "\n",
    "# Predict on test data\n",
    "dtree_pred = dtree.predict(xtest)\n",
    "\n",
    "# Evaluate accuracy\n",
    "dtree_acc = accuracy_score(ytest, dtree_pred)\n",
    "\n",
    "print(\"Decision Tree Accuracy on test set:\", round(dtree_acc * 100, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df9983-bf4e-4cf6-b5e1-751c21d02392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13: Train and Evaluate a Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize random forest model\n",
    "rforest = RandomForestClassifier()\n",
    "\n",
    "# Train the model\n",
    "rforest.fit(xtrain, ytrain)\n",
    "\n",
    "# Predict on test data\n",
    "rforest_pred = rforest.predict(xtest)\n",
    "\n",
    "# Evaluate accuracy\n",
    "rforest_acc = accuracy_score(ytest, rforest_pred)\n",
    "\n",
    "print(\"Random Forest Accuracy on test set:\", round(rforest_acc * 100, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa59afec-a143-4b01-9fc4-1448df46af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14: Compare Model Accuracies\n",
    "# Simple accuracy comparison\n",
    "print(\"KNN Accuracy:\", round(accuracy_score(ytest, predictions) * 100, 2), \"%\")\n",
    "print(\"Logistic Regression Accuracy:\", round(accuracy_score(ytest, logreg_pred) * 100, 2), \"%\")\n",
    "print(\"Decision Tree Accuracy:\", round(accuracy_score(ytest, dtree_pred) * 100, 2), \"%\")\n",
    "print(\"Random Forest Accuracy:\", round(accuracy_score(ytest, rforest_pred) * 100, 2), \"%\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = ['KNN', 'LogReg', 'DecisionTree', 'RandomForest']\n",
    "scores = [\n",
    "    accuracy_score(ytest, predictions),\n",
    "    accuracy_score(ytest, logreg_pred),\n",
    "    accuracy_score(ytest, dtree_pred),\n",
    "    accuracy_score(ytest, rforest_pred)\n",
    "]\n",
    "\n",
    "plt.bar(models, [round(score * 100, 2) for score in scores])\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Model Comparison\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d488a43-5902-47fc-a822-7d7e19a1458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opting Random Forest as the best model and moving on\n",
    "# Step 15: Confusion Matrix & Classification Report (Random Forest)\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(ytest, rforest_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(ytest, rforest_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Random Forest Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3204b469-a653-419f-bb15-67a8fd59e11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 16 â€“ Tune Random Forest with GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# Initialize the base model\n",
    "rforest = RandomForestClassifier()\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid = GridSearchCV(rforest, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit on training data\n",
    "grid.fit(xtrain, ytrain)\n",
    "\n",
    "# Best model after tuning\n",
    "best_model = grid.best_estimator_\n",
    "print(\"Best Parameters:\", grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b60014a-e991-4dba-b5b8-d11ca4a480a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 17: Prepare Final Model for Real-World Use\n",
    "import joblib\n",
    "\n",
    "# Save the tuned Random Forest model\n",
    "joblib.dump(best_model, \"salary_predictor_model.pkl\")\n",
    "\n",
    "# Load the model later\n",
    "loaded_model = joblib.load(\"salary_predictor_model.pkl\")\n",
    "\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "# Predict on new preprocessed data\n",
    "# loaded_model.predict(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676dcad2-8098-44dd-8c9f-4c2c59c6e859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
